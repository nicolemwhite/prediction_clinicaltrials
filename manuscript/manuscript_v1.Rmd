---
title: "manuscript_v1"
author: "Nicole White, Rex Parson, David Borg, Adrian Barnett"
date: "08/07/2022"
output:
  html_document:
    df_print: paged

bibliography: clintrialsref.bib 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

* Systematic review of published clinical prediction models have consistently highlighted poor quality, limited applicability in practice. Examples in COVID-19 (BMJ review), oncology (Dhiman 2022), others

* It is likely that many clinical prediction models are planned but never published. Source of research waste.

* One way to assess research waste from non-publication is to follow-up registered studies aiming to develop and/or validate new or already published prediction model (latter is slightly different point - flesh out later)


* Other refs: Evaluating the impact of prediction models: lessons learned, challenges, and recommendations

# Methods

## Dataset

Clinicaltrials.gov is an online database designed to improve access to information about planned, ongoing and completed clinical studies. The database was launched in 2000 by the National Institute of Healthâ€™s National Library of Medicine, following United States legislation mandating registration of funded clinical trials. Since then, over 420,000 studies have been registered, comprising both interventional and observational studies from 221 countries (https://www.clinicaltrials.gov/; last accessed: 8 July 2022). 

Studies are registered on clinicaltrials.gov by a lead study investigator using a standardised template. Compulsory fields cover the proposed study type, the disease or condition of interest, planned commencement and end dates, and study design details including interventions (if any), outcomes measures and planned sample size. Additional information on participant recruitment, funding and regulatory oversight is also required. A formal statistical analysis plan is not required at the time of registration, but be included as part of an optional detailed summary. Study records can be updated at any time up until project completion, including providing details of resulting publications.

* Availability of study records in XML has led to meta-research projects on different aspects of the `research enterprise'.
* Outside of funded clinical trials, researchers may register their study for different reasons (e.g., reporting incentives). So whilst registered studies may not represent an unbiased sample of research being conduction, they can offer a snapshot of reserach being conducted (@tse2018). 
* In the study, we aimed to identify studies that aimed to develop and/or validate a clinical prediction model, for predicting the diagnosis or prognosis of any human disease. Diagnosis was defined as the risk of having a defined disease or related health condition [ref from PROBAST: @wolff2019]. Prognosis was defined in line with the Prognosis research stratety (PROGRESS), as the risk of any health outcome in the future among people with an already diagnosed disease or health condition (@hemingway2013). 



Study records are availble in XML, which we used for 

* All study records posted to clinicaltrials.gov until 3 March 2022 were downloaded for analysis (n ). Records were downloaded in XML.

* All studies eligible for inclusion were screened using the web application rayyan. All studies were independently reviewed by 2 authors with conflicts resolved by all authors.

## Record screening

All records classified as observational study designs were included. All other study types were excluded [need to provided rationale here for excluding RCTS]

Search terms were:"machine learning","artificial intelligence","deep learning",
  "prediction model","predictive model","prediction score","predictive score",
  "warning score","risk score","risk prediction",
  "prognostic model","diagnostic model"


# References